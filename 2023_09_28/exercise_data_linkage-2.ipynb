{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161e3519-46ab-4690-8f1e-c4c018ca95ad",
   "metadata": {},
   "source": [
    "# **28.09.23**\n",
    "\n",
    "# **Exercise of Data Linkage Concepts and Techniques**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc292375-7b2f-4483-9464-9baf8d8f9d29",
   "metadata": {},
   "source": [
    "## **1. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36998e42-ce5c-4f30-a05b-99f804f8b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor, ceil\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b5ddd-e4d4-4d69-b7e9-8b972cec96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = pd.read_csv('dataA.csv', index_col=0)\n",
    "dfB = pd.read_csv('dataB.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e45ab4-3756-42de-b99b-017eb646f3e9",
   "metadata": {},
   "source": [
    "you can check the data at your convenience "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afc1ec06-f8c5-41be-b2ce-3f3429179e3d",
   "metadata": {},
   "source": [
    "## **2. Calculation of Jaro-Winkler Distance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9db99-4d76-49d4-9229-892038953a75",
   "metadata": {},
   "source": [
    "Define functions to calculate the Jaro-Winkler Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bff36-5dbc-411b-8129-e24a3bb9c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 implementation of JW di\n",
    " \n",
    "# Function to calculate the\n",
    "# Jaro Similarity of two s\n",
    "def jaro_distance(s1, s2):\n",
    "     \n",
    "    # If the s are equal\n",
    "    if (s1 == s2):\n",
    "        return 1.0\n",
    " \n",
    "    # Length of two s\n",
    "    len1 = len(s1)\n",
    "    len2 = len(s2)\n",
    " \n",
    "    # Maximum distance upto which matching\n",
    "    # is allowed\n",
    "    max_dist = floor(max(len1, len2) / 2) - 1\n",
    " \n",
    "    # Count of matches\n",
    "    match = 0\n",
    " \n",
    "    # Hash for matches\n",
    "    hash_s1 = [0] * len(s1)\n",
    "    hash_s2 = [0] * len(s2)\n",
    " \n",
    "    # Traverse through the first\n",
    "    for i in range(len1):\n",
    " \n",
    "        # Check if there is any matches\n",
    "        for j in range(max(0, i - max_dist),\n",
    "                       min(len2, i + max_dist + 1)):\n",
    "             \n",
    "            # If there is a match\n",
    "            if (s1[i] == s2[j] and hash_s2[j] == 0):\n",
    "                hash_s1[i] = 1\n",
    "                hash_s2[j] = 1\n",
    "                match += 1\n",
    "                break\n",
    " \n",
    "    # If there is no match\n",
    "    if (match == 0):\n",
    "        return 0.0\n",
    " \n",
    "    # Number of transpositions\n",
    "    t = 0\n",
    "    point = 0\n",
    " \n",
    "    # Count number of occurrences\n",
    "    # where two characters match but\n",
    "    # there is a third matched character\n",
    "    # in between the indices\n",
    "    for i in range(len1):\n",
    "        if (hash_s1[i]):\n",
    " \n",
    "            # Find the next matched character\n",
    "            # in second\n",
    "            while (hash_s2[point] == 0):\n",
    "                point += 1\n",
    " \n",
    "            if (s1[i] != s2[point]):\n",
    "                t += 1\n",
    "            point += 1\n",
    "    t = t//2\n",
    " \n",
    "    # Return the Jaro Similarity\n",
    "    return (match/ len1 + match / len2 +\n",
    "            (match - t) / match)/ 3.0\n",
    " \n",
    "def jaro_winkler_distance(s1, s2):\n",
    "    jaro_dist = jaro_distance(s1, s2)\n",
    "    \n",
    "    # Length of common prefix\n",
    "    L = 0\n",
    "    for l1, l2 in zip(s1, s2):\n",
    "        if l1 == l2:\n",
    "            L += 1\n",
    "        else:\n",
    "            break\n",
    "    L = max(4, L)  # Take at most 4 characters\n",
    "    p = 0.1  # Scaling factor\n",
    "    \n",
    "    return jaro_dist + (L * p * (1 - jaro_dist))\n",
    "def compute_similarity_matrix(dfA, dfB):\n",
    "    n, m = dfA.shape\n",
    "    p, _ = dfB.shape\n",
    "    \n",
    "    # Create an empty matrix to store the results\n",
    "    results = []\n",
    "    \n",
    "    # Iterate through each pair of records\n",
    "    for idx_a, row_a in dfA.iterrows():\n",
    "        for idx_b, row_b in dfB.iterrows():\n",
    "            # For each variable, compute the Jaro-Winkler similarity\n",
    "            similarities = [jaro_winkler_distance(str(row_a[i]), str(row_b[i])) for i in range(m)]\n",
    "            results.append(similarities)\n",
    "            \n",
    "    # Convert to DataFrame with combined index\n",
    "    index_pairs = [(idx_a, idx_b) for idx_a in dfA.index for idx_b in dfB.index]\n",
    "    df_result = pd.DataFrame(results, columns=dfA.columns, index=pd.MultiIndex.from_tuples(index_pairs))\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9be5ed-789e-4081-9e3a-4d046fa3dd80",
   "metadata": {},
   "source": [
    "The function compute_similarity_matrix() will take two datasets and compute Jaro-Winkler Distance for all pairs and all attributes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1635a2-2e69-4f74-b5ca-8af100a67406",
   "metadata": {},
   "source": [
    "### **Exercise #1**\n",
    "\n",
    "+ *What is meaning of the Jaro-Winkler Distance?*\n",
    "+ *Calculate the Jaro-Winkler Distance as df_similarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28495abd-b067-43d7-a50a-e21064c30d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions here\n",
    "#df_similarity = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8c981-bb66-4b42-99dc-2e29191c2278",
   "metadata": {},
   "source": [
    "### **Exercise #2**\n",
    "\n",
    "+ *If our similarity levels $L_k$ is 3 (different, similar, identical),*\n",
    "+ *convert the result into similarity levels based on the threshold values of 0.88 and 0.94*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309a0ab-fcce-40c6-bafd-b066e5be02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_matrix_values(matrix):\n",
    "    # Your solutions here\n",
    "    pass\n",
    "    return # Your solutions here\n",
    "\n",
    "converted_df = convert_matrix_values(df_similarity)\n",
    "converted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31eef06-ed6b-4d6c-bd22-6969d27a1dcd",
   "metadata": {},
   "source": [
    "### **Exercise #3**\n",
    "\n",
    "+ *If we set the rule that a pair is considered as a match if they have no \"different\", then*\n",
    "+ *Identify the matched pairs and compute number of matched pairs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027eacb2-9f6c-4db4-9788-2a5a3be8696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions here\n",
    "\n",
    "filtered_df = # Your solutions here\n",
    "\n",
    "print(\"Pairs with either two 'identical' attributes or three 'similar' attributes, and no 'different' attributes:\")\n",
    "print(filtered_df)\n",
    "\n",
    "print(\"\\nNumber of such pairs:\", len(filtered_df))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b8a731a-8683-4c6e-a480-a955be195c9b",
   "metadata": {},
   "source": [
    "## **3. Using Fellegi-Sunter method with ECM through Record linkage Toolkit (optional)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f7c52-afa2-4060-b442-cc43f7f24703",
   "metadata": {},
   "source": [
    "Installation of Python Record linkage Toolkit\n",
    "\n",
    "The Python Record linkage Toolkit requires Python 3.6 or higher. \n",
    "\n",
    "Install the package easily with pip\n",
    "\n",
    "$ pip install recordlinkage\n",
    "\n",
    "The related website is https://recordlinkage.readthedocs.io/en/latest/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5813bb-74b6-4f1d-8c35-c7b6cc727d1f",
   "metadata": {},
   "source": [
    "You can check about the installation using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14807e-443e-448d-953d-2f5df38ce41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage as rl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7abad2-6b3b-4e40-aab8-740f4e372e8b",
   "metadata": {},
   "source": [
    "### **Exercise #4**\n",
    "\n",
    "+ *Try to run the following code to compute the result using the original JW scores*\n",
    "+ *Try to understand the result*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a30bab-8b81-49c9-9aa4-8a2e4d2d4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = rl.ECMClassifier(binarize=0.8)\n",
    "cl.fit(df_similarity)\n",
    "fsweights = cl.log_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb77533-3db9-44d8-a592-5d9f650f6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"p probability P(Match):\", cl.p)\n",
    "print(\"log weights of features:\", fsweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f6aaf-f6ad-4fe6-aa47-1ab28943c954",
   "metadata": {},
   "source": [
    "### **Exercise #5**\n",
    "\n",
    "+ *Using the match weight to compute the link probability of each pairs*\n",
    "+ *Identify the matched pairs with a threshold of 0.9*\n",
    "+ *Will this result better?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f827b2-70c2-4857-8088-1a508ad946dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions here\n",
    "\n",
    "\n",
    "filtered_pairs2 = # Your solutions here\n",
    "\n",
    "# Print the results\n",
    "print(\"Pairs with values higher than 0.9:\")\n",
    "print(filtered_pairs2.index)\n",
    "\n",
    "print(\"\\nNumber of such pairs:\", len(filtered_pairs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf2a9e-0e25-4d5b-98b5-7fbd70107551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_homebrew_kernel",
   "language": "python",
   "name": "my_homebrew_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
