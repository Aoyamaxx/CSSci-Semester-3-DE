{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edc8312",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0953c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Quanpu Xiao\"\n",
    "STUDENT_ID = \"14368978\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fd616",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf49909-80cf-409a-b44d-8553e16effc6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b585cf74037b4c712eb518f3ef8e765",
     "grade": false,
     "grade_id": "cell-3cff1dd74792b356",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Analyzing Gender Distribution Among Scientific Authors in Computational Social Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620fa176-4f89-4b75-96ba-634fc9b8962a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee897c4f558978be6819e4f4f7c261f5",
     "grade": false,
     "grade_id": "cell-8c3327acf8f9bd6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Objective*: Understand the gender distribution of authors across different scientific disciplines using web scraping and API-based gender identification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b39693a-b0d4-4372-a0e0-ecca61ba40c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c16f3e433bf6dac45bbe3f424b3b397",
     "grade": false,
     "grade_id": "cell-e817d3557fb4f0df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Gender diversity in research is crucial for ensuring diverse perspectives and approaches in scientific inquiry, and for the comprehensiveness and richness of research findings. A balanced gender representation can help challenge systemic biases that might otherwise marginalize or overlook significant areas of study. A diverse research community can also act as a role model, inspiring future generations of all genders to pursue scientific endeavors.\n",
    "\n",
    "This assignment focuses on the question of the gender distribution of researchers in different disciplines, and on identifying how often women are the first or last author of publications. \n",
    "\n",
    "To do so, you will scrape a preprint website, and you will use the API genderize.io to identify the gender of the author based on their name.\n",
    "\n",
    "1. Prepare: Identify a source and decide a scraping strategy\n",
    "\n",
    "2. Scrape the list of articles and authors\n",
    "\n",
    "3. Use API to identify gender \n",
    "\n",
    "4. Analyze gender distribution and authorship order\n",
    "\n",
    "5. Reflect on your findings. \n",
    "\n",
    "6. Scrape the paper abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f155b-74cb-427d-8650-9b76782acb00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dda8234fd20fa3e245cee7db24992a9",
     "grade": false,
     "grade_id": "cell-df1834b4ac2ae69b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Setup and requirements\n",
    "First make sure that you have the needed libraries for Python correctly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6ecfdd-54b5-49ab-b84b-279c4831b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium\n",
    "# !pip install selenium\n",
    "# !pip install webdriver-manager\n",
    "# !pip install webdriver-manager --upgrade\n",
    "# !pip install packaging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# driver.get(\"https://www.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b9c67f-2327-4373-9a39-f7b94360b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request\n",
    "# !pip install requests\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb1d394-4f99-49d2-a25c-edf6af82561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautifulsoup\n",
    "# !pip install beautifulsoup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6550b7-edfc-47df-af69-3d9665090102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12a9d5-8975-425f-8e13-dc4e586090ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30d4be4fd67982bfddf22fbe5c9fdf48",
     "grade": false,
     "grade_id": "cell-dcc2e17cee32d989",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Plan and strategize\n",
    "\n",
    "We first need to decide which site to scrape and our strategy for doing so. We will focus on a preprint repository. Preprint repositories host and disseminate research papers before they are peer-reviewed and published in academic journals. They therefore give a view of the latest research.\n",
    "\n",
    "There are several repositories that represent different scientific disciplines (e.g., PubMed for life sciences, arXiv for physics and computer science, JSTOR for humanities and social sciences, SocArxiv for social science, etc.) \n",
    "\n",
    "We will here focus on arxiv.org, where many Computational Social Scientists publish, often under the category \"Computers and Society\".\n",
    "\n",
    "You need to pick a page on ArXiv where you can get a representative sample of these research papers -- and which you are allowed to scrape.\n",
    "\n",
    "1. Browse Arxiv.org, and select a page on the website where you can find a sample of research papers.\n",
    "2. Check the robots.txt. Are you allowed to scrape the page you selected? (If not, you will have to choose another one!)\n",
    "3. Decide a strategy for scraping the page as quickly and easily as possible to find the names of the authors for each paper, their titles, and a link to the pages.\n",
    "4. Choose which Python libraries for scraping that you will use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723d96b-af05-42a4-981b-4d8d1722e22d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6b6e1409e86d810ef169596cbabc039",
     "grade": false,
     "grade_id": "cell-4696e716d4f1c81a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1: Which library is most suitable?\n",
    "\n",
    "Given the structure of the website, which Python libraries for scraping do you think is appropriate to use? Motivate your choice in a few sentences.\n",
    "\n",
    "_[In this case of scraping listed data from Arxiv.txt, it would be best to use 'request' combined with 'BeautifulSoup', since request could make HTTP requests to the website, and BeautifulSoup provides easy methods for parsing and navigating the HTML structure to extract the required data. Also, BeautifulSoup will be an ideal solution to handle static website lie Arxiv.txt, with better performance since it won't need to load the whole website.]_\n",
    "\n",
    "[Evaluation: This is an open question. Any motivation that makes sense is fine, but in general, requests make more sense for this page than selenium, since the site in question is not dynamic. Using selenium will be slower and more difficult.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4455efa-4750-4473-aa08-db19ba9bafce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "594b965b0d990ca90076303a53a26d39",
     "grade": false,
     "grade_id": "cell-f043dfd5a37ede8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Scrape the list of articles and authors \n",
    "\n",
    "Implement your scraping strategy. Scrape the page and collect the information about the publication. \n",
    "\n",
    "- You will need to get (1) the link to the article, (2) the title of the article, (3) the names of all authors of the paper, in the same order as they appear on the paper. \n",
    "- You need to scrape 200 research papers.\n",
    "\n",
    "- Note that you may need to iterate over multiple pages.\n",
    "- Note that you need to handle possible exceptions and that your code needs to be able to restart if it crashes.\n",
    "- You final result should be a list of dicts, with keys 'title', 'url', and 'authors'. 'authors' should consist of a list where the authors are listed in the order that they were on the paper. \n",
    "- You need to clean and validate your data: check that all papers have authors, that all papers have titles, clean the texts to remove empty spaces and similar, etc.\n",
    "- Store the resulting array persistently as a pickle with the name 'scraping_result.pkl'.\n",
    "\n",
    "For instance: [{'title': 'How to use Large Langauge Models for Text Analysis', 'authors': ['Törnberg, Petter'], 'url':'https://arxiv.org/abs/2307.13106' } ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9449314",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53252983d2c99f0b67a82089ef4b22fb",
     "grade": false,
     "grade_id": "cell-f23671663c59f383",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 1, total papers collected: 3\n",
      "Scraped page 2, total papers collected: 53\n",
      "Scraped page 3, total papers collected: 103\n",
      "Scraped page 4, total papers collected: 153\n",
      "Scraped page 5, total papers collected: 203\n",
      "Collected 200 papers.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_list = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "if os.path.exists('scraping_result.pkl'):\n",
    "    print('A scraping result file already exists. Canceling the scraping.')\n",
    "    exit()\n",
    "\n",
    "def scrape_page(url):\n",
    "    for _ in range(5):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            articles = []\n",
    "            for item in soup.find_all('dt'):\n",
    "                dd_item = item.find_next_sibling('dd')\n",
    "                if dd_item:\n",
    "                    title = dd_item.find('div', {'class': 'list-title'}).text.replace(\"Title:\", \"\").strip()\n",
    "                    authors = [author.text.strip() for author in dd_item.find('div', {'class': 'list-authors'}).find_all('a')]\n",
    "                    \n",
    "                    article_id = item.find('span', {'class': 'list-identifier'}).find('a').get('href').split('/')[-1]\n",
    "                    article_url = f'https://arxiv.org/abs/{article_id}'\n",
    "                    \n",
    "                    articles.append({'title': title, 'authors': authors, 'url': article_url})\n",
    "            return articles\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    print(f\"Failed to retrieve the page: {url} after 5 attempts.\")\n",
    "    return []\n",
    "\n",
    "data_list = []\n",
    "if os.path.exists('scraping_result.pkl'):\n",
    "    with open('scraping_result.pkl', 'rb') as f:\n",
    "        data_list = pickle.load(f)\n",
    "\n",
    "page_num = 0\n",
    "papers_per_page = 50\n",
    "\n",
    "while len(data_list) < 200:\n",
    "    page_num += 1\n",
    "    url = f'https://arxiv.org/list/cs.CY/recent?skip={page_num * papers_per_page}&show={papers_per_page}'\n",
    "    new_articles = scrape_page(url)\n",
    "    data_list.extend(new_articles)\n",
    "    print(f'Scraped page {page_num}, total papers collected: {len(data_list)}')\n",
    "\n",
    "    if len(data_list) >= 200:\n",
    "        print('Collected 200 papers.')\n",
    "        break\n",
    "\n",
    "with open('scraping_result.pkl', 'wb') as f:\n",
    "    pickle.dump(data_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13393063",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a24a8ecb5c00b7a230f1536e1032db2e",
     "grade": true,
     "grade_id": "cell-eb1c8710173e94df",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if keys exists in dictionary\n",
    "assert 'title' in data_list[0], \"Key 'title' not found in dictionary\"\n",
    "assert 'authors' in data_list[0], \"Key 'author' not found in dictionary\"\n",
    "assert 'url' in data_list[0], \"Key 'url' not found in dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d989cacd-dff0-456e-8967-2dbe08362fc0",
   "metadata": {},
   "source": [
    "## 3. Use Genderize.io to identify author gender\n",
    "\n",
    "The next step is to identify the gender of the authors. To do so, we will use the free API genderdize.io. \n",
    "\n",
    "1. Go to https://genderize.io/ and read the API documnentation.\n",
    "2. Do you need to register to use it? Do you need an API key? \n",
    "3. How do you call the API? What parameters do you need to send? \n",
    "4. What rate limiting is used? How long do you need to wait between calls?\n",
    "\n",
    "You will use what you learned to carry out the following tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065292a-42e8-4069-8dfd-4d6a1db353fa",
   "metadata": {},
   "source": [
    "#### Task 1: _identify_gender()_\n",
    "Write a function _identify_gender(first_name)_ that takes a name, and uses the API to guess the gender. The function should send a request to genderize.io, and parse the resulting json to a dict. The function should return a dict with the data provided by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0143972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'limit': '100000', 'remaining': '98585', 'reset': 'Not provided'}\n"
     ]
    }
   ],
   "source": [
    "# API limits test\n",
    "\n",
    "def get_rate_limits():\n",
    "    url = 'https://api.genderize.io/?name=John' + f'&apikey={\"ef85eae72c459a406b138172e7613786\"}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    limit = response.headers.get('X-Rate-Limit-Limit', 'Not provided')\n",
    "    remaining = response.headers.get('X-Rate-Limit-Remaining', 'Not provided')\n",
    "    reset = response.headers.get('X-Rate-Reset', 'Not provided')\n",
    "\n",
    "    return {\n",
    "        \"limit\": limit,\n",
    "        \"remaining\": remaining,\n",
    "        \"reset\": reset\n",
    "    }\n",
    "\n",
    "rate_limits = get_rate_limits()\n",
    "print(rate_limits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01c681e-6bce-416d-9c45-03810e9c2376",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8699ffe64f521fe51e152a3c4baae18",
     "grade": false,
     "grade_id": "cell-c02e3ed6f4cf8078",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 14512, 'name': 'Sasha', 'gender': 'female', 'probability': 0.52}\n"
     ]
    }
   ],
   "source": [
    "def identify_gender(first_name):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    api_key = \"ef85eae72c459a406b138172e7613786\"\n",
    "    \n",
    "    import json\n",
    "    url = f'https://api.genderize.io/?name={first_name}' + f'&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  \n",
    "    gender_data = response.json()\n",
    "    return gender_data\n",
    "\n",
    "# Test\n",
    "print(identify_gender(\"Sasha\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d76a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d03ef969-2f1e-4ebf-bd1f-3dd0657f2e69",
   "metadata": {},
   "source": [
    "#### Task 2: Identify gender of all authors\n",
    "\n",
    "Your task is now to use your new function to identify the genders of all authors that you previously scraped. \n",
    "\n",
    "To do so, you first need to extract the first name of each author. You need to iterate over these names and use your function to identify the gender of the author.\n",
    "\n",
    "Your result should be a dataframe with the following columns:\n",
    "\n",
    "- article_url | author_full_name | first_name | author_order | estimated_gender | gender_probability\n",
    "\n",
    "Author_order should be a number specifying where the author was in the author list for the publication (e.g., 0 = first author, 1 = second author...) _Estimated_gender_ should contain the API response on gender, and _gender_probability_ the certainty of the gender, according to the API.\n",
    "\n",
    "Note:\n",
    "- You will need to transform your dict to the dataframe shown above, with one author per line. (This means that each URL will be associated to multiple author names.)\n",
    "- Make sure that you respect the rate limiting of the API. \n",
    "- Make sure that you handle exceptions and that your function continues \n",
    "- Note that you get a maximum of 1,000 free calls per day, so you need to make sure that you do not waste your API calls!\n",
    "- The API may not have all names stored. For these names, store a _np.nan_ value as the gender.\n",
    "\n",
    "Pickle the resulting dataframe with the name: 'author_gender.df.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1db8df5b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a2558664a48ddbac7c92c35c0c14e2b",
     "grade": false,
     "grade_id": "cell-b9581c1efe1807cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed gender identification for https://arxiv.org/abs/2310.05396\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04875\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04465\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08795\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08532\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08455\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08349\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08133\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07888\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07806\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08433\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07915\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07563\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07516\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07099\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06856\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07715\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07629\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07625\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07613\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07577\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06778\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06556\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06475\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06361\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06269\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06061\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06056\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06009\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06633\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06391\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06257\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05998\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05936\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05598\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05476\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05432\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05070\n",
      "Error: 422 Client Error: Unprocessable Entity for url: https://api.genderize.io/?name%5B%5D=Luis&name%5B%5D=Jo%C3%A3o&name%5B%5D=Justin&name%5B%5D=Frederico&name%5B%5D=William&name%5B%5D=Rogers&name%5B%5D=Ju-Yi&name%5B%5D=Alvina&name%5B%5D=Warachaya&name%5B%5D=Jaime&name%5B%5D=Leo&apikey=ef85eae72c459a406b138172e7613786\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04997\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04897\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04824\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04425\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05689\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05484\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05472\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05421\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05396\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04875\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04465\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08795\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08532\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08455\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08349\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08133\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07888\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07806\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08433\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07915\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07563\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07516\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07099\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06856\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07715\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07629\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07625\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07613\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07577\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06778\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06556\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06475\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06361\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06269\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06061\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06056\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06009\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06633\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06391\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06257\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05998\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05936\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05598\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05476\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05432\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05070\n",
      "Error: 422 Client Error: Unprocessable Entity for url: https://api.genderize.io/?name%5B%5D=Luis&name%5B%5D=Jo%C3%A3o&name%5B%5D=Justin&name%5B%5D=Frederico&name%5B%5D=William&name%5B%5D=Rogers&name%5B%5D=Ju-Yi&name%5B%5D=Alvina&name%5B%5D=Warachaya&name%5B%5D=Jaime&name%5B%5D=Leo&apikey=ef85eae72c459a406b138172e7613786\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04997\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04897\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04824\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04425\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05689\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05484\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05472\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05421\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05396\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04875\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04465\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08795\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08532\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08455\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08349\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08133\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07888\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07806\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08433\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07915\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07563\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07516\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07099\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06856\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07715\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07629\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07625\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07613\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07577\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06778\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06556\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06475\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06361\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06269\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06061\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06056\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06009\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06633\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06391\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06257\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05998\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05936\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05598\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05476\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05432\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05070\n",
      "Error: 422 Client Error: Unprocessable Entity for url: https://api.genderize.io/?name%5B%5D=Luis&name%5B%5D=Jo%C3%A3o&name%5B%5D=Justin&name%5B%5D=Frederico&name%5B%5D=William&name%5B%5D=Rogers&name%5B%5D=Ju-Yi&name%5B%5D=Alvina&name%5B%5D=Warachaya&name%5B%5D=Jaime&name%5B%5D=Leo&apikey=ef85eae72c459a406b138172e7613786\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04997\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04897\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04824\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04425\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05689\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05484\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05472\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05421\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05396\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04875\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04465\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08795\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08532\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08455\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08349\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08133\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07888\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07806\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.08433\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07915\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07563\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07516\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07099\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06856\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07715\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07629\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07625\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07613\n",
      "Processed gender identification for https://arxiv.org/abs/2310.07577\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06778\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06556\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06475\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06361\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06269\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06061\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06056\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06009\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06633\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06391\n",
      "Processed gender identification for https://arxiv.org/abs/2310.06257\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05998\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05936\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05598\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05476\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05432\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05070\n",
      "Error: 422 Client Error: Unprocessable Entity for url: https://api.genderize.io/?name%5B%5D=Luis&name%5B%5D=Jo%C3%A3o&name%5B%5D=Justin&name%5B%5D=Frederico&name%5B%5D=William&name%5B%5D=Rogers&name%5B%5D=Ju-Yi&name%5B%5D=Alvina&name%5B%5D=Warachaya&name%5B%5D=Jaime&name%5B%5D=Leo&apikey=ef85eae72c459a406b138172e7613786\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04997\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04897\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04824\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04739\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04425\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05689\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05628\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05484\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05472\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05421\n",
      "Processed gender identification for https://arxiv.org/abs/2310.05396\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04875\n",
      "Processed gender identification for https://arxiv.org/abs/2310.04465\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load your scraped data\n",
    "with open('scraping_result.pkl', 'rb') as f:\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "api_key = \"ef85eae72c459a406b138172e7613786\"\n",
    "\n",
    "def identify_gender(names):\n",
    "    url = f'https://api.genderize.io/?name[]=' + '&name[]='.join(names) + f'&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    gender_data = response.json()\n",
    "    return gender_data\n",
    "\n",
    "author_gender_data = []\n",
    "\n",
    "for article in data_list:\n",
    "    article_url = article['url']\n",
    "    authors = article['authors']\n",
    "    first_names_batch = [author_full_name.split()[0] for author_full_name in authors]\n",
    "    try:\n",
    "        gender_data_batch = identify_gender(first_names_batch)\n",
    "        for author_order, gender_data in enumerate(gender_data_batch):\n",
    "            estimated_gender = gender_data.get('gender', np.nan)\n",
    "            gender_probability = gender_data.get('probability', np.nan)\n",
    "            author_full_name = authors[author_order]\n",
    "            first_name = first_names_batch[author_order]\n",
    "            author_gender_data.append({\n",
    "                'article_url': article_url,\n",
    "                'author_full_name': author_full_name,\n",
    "                'first_name': first_name,\n",
    "                'author_order': author_order,\n",
    "                'estimated_gender': estimated_gender,\n",
    "                'gender_probability': gender_probability\n",
    "            })\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    print(f'Processed gender identification for {article_url}')\n",
    "    time.sleep(0.1)\n",
    "\n",
    "df = pd.DataFrame(author_gender_data)\n",
    "\n",
    "with open('author_gender.df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b002fc50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94b2428a7e2b93e5c2e81bca2122b796",
     "grade": true,
     "grade_id": "cell-85d226433e71226b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_url</th>\n",
       "      <th>author_full_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>author_order</th>\n",
       "      <th>estimated_gender</th>\n",
       "      <th>gender_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://arxiv.org/abs/2310.05396</td>\n",
       "      <td>Ru Wang</td>\n",
       "      <td>Ru</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://arxiv.org/abs/2310.05396</td>\n",
       "      <td>Nihan Zhou</td>\n",
       "      <td>Nihan</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://arxiv.org/abs/2310.05396</td>\n",
       "      <td>Tam Nguyen</td>\n",
       "      <td>Tam</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://arxiv.org/abs/2310.05396</td>\n",
       "      <td>Sanbrita Mondal</td>\n",
       "      <td>Sanbrita</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://arxiv.org/abs/2310.05396</td>\n",
       "      <td>Bilge Mutlu</td>\n",
       "      <td>Bilge</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://arxiv.org/abs/2310.05396</td>\n",
       "      <td>Yuhang Zhao</td>\n",
       "      <td>Yuhang</td>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://arxiv.org/abs/2310.04875</td>\n",
       "      <td>Gabriele Tolomei</td>\n",
       "      <td>Gabriele</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://arxiv.org/abs/2310.04875</td>\n",
       "      <td>Cesare Campagnano</td>\n",
       "      <td>Cesare</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://arxiv.org/abs/2310.04875</td>\n",
       "      <td>Fabrizio Silvestri</td>\n",
       "      <td>Fabrizio</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://arxiv.org/abs/2310.04875</td>\n",
       "      <td>Giovanni Trappolini</td>\n",
       "      <td>Giovanni</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        article_url     author_full_name first_name  \\\n",
       "0  https://arxiv.org/abs/2310.05396              Ru Wang         Ru   \n",
       "1  https://arxiv.org/abs/2310.05396           Nihan Zhou      Nihan   \n",
       "2  https://arxiv.org/abs/2310.05396           Tam Nguyen        Tam   \n",
       "3  https://arxiv.org/abs/2310.05396      Sanbrita Mondal   Sanbrita   \n",
       "4  https://arxiv.org/abs/2310.05396          Bilge Mutlu      Bilge   \n",
       "5  https://arxiv.org/abs/2310.05396          Yuhang Zhao     Yuhang   \n",
       "6  https://arxiv.org/abs/2310.04875     Gabriele Tolomei   Gabriele   \n",
       "7  https://arxiv.org/abs/2310.04875    Cesare Campagnano     Cesare   \n",
       "8  https://arxiv.org/abs/2310.04875   Fabrizio Silvestri   Fabrizio   \n",
       "9  https://arxiv.org/abs/2310.04875  Giovanni Trappolini   Giovanni   \n",
       "\n",
       "   author_order estimated_gender  gender_probability  \n",
       "0             0             male                0.62  \n",
       "1             1           female                0.94  \n",
       "2             2             male                0.61  \n",
       "3             3           female                1.00  \n",
       "4             4           female                0.87  \n",
       "5             5             male                0.86  \n",
       "6             0             male                0.85  \n",
       "7             1             male                1.00  \n",
       "8             2             male                1.00  \n",
       "9             3             male                1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert 'article_url' in df.columns, \"article_url column is missing\"\n",
    "assert 'author_full_name' in df.columns, \"author_full_name column is missing\"\n",
    "assert 'first_name' in df.columns, \"first_name column is missing\"\n",
    "assert 'author_order' in df.columns, \"author_order column is missing\"\n",
    "assert 'estimated_gender' in df.columns, \"estimated_gender column is missing\"\n",
    "assert 'gender_probability' in df.columns, \"gender_probability column is missing\"\n",
    "\n",
    "with open('author_gender.df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04701544-19ce-4f09-b6fc-06d1cae74f58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f43b38f6f15f75ac827995ace4fe885",
     "grade": true,
     "grade_id": "cell-c2e95f57fe249bfe",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3efaadaf-c7cf-4287-88a4-27b2bdf846e4",
   "metadata": {},
   "source": [
    "## 4. Analyze gender distribution and authorship order\n",
    "\n",
    "Now that you have gathered the necessary data, you will use this data to answer some research questions about gender equality in CSS research. Note that in calculating this, you need to handle that the API may have failed to identify the gender of some authors.\n",
    "\n",
    "1. What fraction of the authors included are women? \n",
    "2. What happens to this fraction if you only include authors for which the gender_probability is higher than 80%? \n",
    "3. Being the first or single author on a research paper is an important status signal among researchers: it often means that you made the most work. What fraction of the first or single authors are women? \n",
    "4. Being the _last_ author on a research paper with _three or more authors_ is also an important status signal: it tends to mean that you were the one to acquire funding or lead the lab. What fraction of the last-authors on papers with three or more author are women?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cbbcb4f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e46a8a2f7e1cabdb0061c0d4c9fc86f2",
     "grade": true,
     "grade_id": "cell-3a0cd012a322701a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of authors who are women: 0.28\n",
      "Fraction of authors who are women (with high gender probability of 80%): 0.29\n",
      "Fraction of first or single authors who are women: 0.27\n",
      "Fraction of last-authors on papers with three or more authors who are women: 0.33\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# 1\n",
    "female_authors_count = df[df['estimated_gender'] == 'female'].shape[0]\n",
    "total_authors_count = df.shape[0]\n",
    "female_fraction = female_authors_count / total_authors_count\n",
    "print(f'Fraction of authors who are women: {female_fraction:.2f}')\n",
    "\n",
    "# 2\n",
    "filtered_df = df[df['gender_probability'] > 0.8]\n",
    "female_authors_high_prob_count = filtered_df[filtered_df['estimated_gender'] == 'female'].shape[0]\n",
    "total_authors_high_prob_count = filtered_df.shape[0]\n",
    "female_high_prob_fraction = female_authors_high_prob_count / total_authors_high_prob_count\n",
    "print(f'Fraction of authors who are women (with high gender probability of 80%): {female_high_prob_fraction:.2f}')\n",
    "\n",
    "# 3\n",
    "first_authors_df = df[df['author_order'] == 0]\n",
    "female_first_authors_count = first_authors_df[first_authors_df['estimated_gender'] == 'female'].shape[0]\n",
    "total_first_authors_count = first_authors_df.shape[0]\n",
    "female_first_authors_fraction = female_first_authors_count / total_first_authors_count\n",
    "print(f'Fraction of first or single authors who are women: {female_first_authors_fraction:.2f}')\n",
    "\n",
    "# 4\n",
    "# Group by article_url and filter groups with 3 or more authors\n",
    "groups = df.groupby('article_url').filter(lambda x: len(x) >= 3).groupby('article_url')\n",
    "\n",
    "last_authors_df = groups.last()\n",
    "\n",
    "female_last_authors_count = last_authors_df[last_authors_df['estimated_gender'] == 'female'].shape[0]\n",
    "total_last_authors_count = last_authors_df.shape[0]\n",
    "female_last_authors_fraction = female_last_authors_count / total_last_authors_count\n",
    "print(f'Fraction of last-authors on papers with three or more authors who are women: {female_last_authors_fraction:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b370f3-4b58-41f0-b615-5aff1c4a3ab6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66aa822667d179fcd1119f84e5100ee3",
     "grade": false,
     "grade_id": "cell-906708bcf0e226e3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## 5. Reflect on your findings\n",
    "\n",
    "You have now carried out your analysis of the gender distribution in articles in CSS using scraped data. Reflect on your findings and method, and answer each of the following questions in a few sentences.\n",
    "\n",
    "1. What are the implications of the observed gender distribution and author order in CSS? How do these distributions compare with your expectations?\n",
    "2. How accurate do you think your findings are? What are the limitations of determining gender based solely on names? Are there cultural or regional nuances that the API might miss?\n",
    "3. Reflect on the ethical considerations involved in scraping this data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27044038-f459-45c7-9a7f-d2cd6d15b18d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "253f673902e8de295d8442ad59caa4b8",
     "grade": true,
     "grade_id": "cell-47e469c422287e72",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "1. The observed gender distribution suggests that there is a gender gap in the Computer and Society (CSS) sector with a lower representation of women as authors. The fraction of female authors is 32%, which increases slightly to 33% when considering high gender probability. Moreover, the lower fraction of women as first or single authors (29%) may indicate a lesser representation in leading roles on projects. However, a slightly higher fraction of women as last-authors on papers with three or more authors (35%) may signify a better representation in senior or supervisory roles. These findings might be indicative of underlying gender disparities in the field, which could be due to a variety of systemic or cultural factors. The distributions might be different from expectations if one would expect a more balanced gender representation in the field.\n",
    "\n",
    "2. The accuracy of the findings is largely dependent on the accuracy of the genderize.io API, which determines gender based solely on names. This method has inherent limitations as it might not accurately reflect an individual's gender, especially in cases where names are unisex or where the gender distribution of a name differs significantly across different cultures or regions. Additionally, the method does not account for non-binary or transgender individuals. The cultural or regional nuances, the potential for misgendering, and the inability to identify non-binary genders are significant limitations that could affect the accuracy and comprehensiveness of the findings.\n",
    "\n",
    "3. The ethical considerations in scraping this data include respecting the privacy and consent of the individuals whose information is being collected and analyzed. While the data is publicly available, the individuals may not have consented to having their gender inferred and analyzed in this manner. Moreover, the method of gender determination based on names can be seen as reinforcing a binary understanding of gender, which can be exclusionary. Additionally, the implications of the findings could be significant and might contribute to broader discussions or actions regarding gender equality in the field. Therefore, ensuring accuracy, transparency, and respect for individuals' identities and privacy are crucial ethical considerations in such analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d395f6-7186-4239-93db-e3aa75f6abfb",
   "metadata": {},
   "source": [
    "## 6. Scrape the paper abstract\n",
    "\n",
    "Your next task is to get the abstract for each paper. You will use these abstracts in a later exercise in the course, where we will use text analysis to examine whether the content of research papers are a function of the gender of the author. \n",
    "\n",
    "To do so, you need to iterate over the papers that you have already identified, and scrape the abstract from the URL listed. \n",
    "\n",
    "#### Task 1: scrape_abstract()\n",
    "Write a function scrape_abstract(url) that goes to the research paper URL, and scrapes the content of the abstract. The function should return the abstract as a string, and nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a98b5f1-ffd3-4150-a60c-2e738c884956",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea05833922353eeb9ca3fd40d86801b7",
     "grade": false,
     "grade_id": "cell-b8712361e6327b18",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract:This guide introduces Large Language Models (LLM) as a highly versatile text analysis method within the social sciences. As LLMs are easy-to-use, cheap, fast, and applicable on a broad range of text analysis tasks, ranging from text annotation and classification to sentiment analysis and critical discourse analysis, many scholars believe that LLMs will transform how we do text analysis. This how-to guide is aimed at students and researchers with limited programming experience, and offers a simple introduction to how LLMs can be used for text analysis in your own research project, as well as advice on best practices. We will go through each of the steps of analyzing textual data with LLMs using Python: installing the software, setting up the API, loading the data, developing an analysis prompt, analyzing the text, and validating the results. As an illustrative example, we will use the challenging task of identifying populism in political texts, and show how LLMs move beyond the existing state-of-the-art.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_abstract(url):\n",
    "    \"\"\"\n",
    "    Fetch the abstract from the provided arXiv URL using XPath.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL of the arXiv paper.\n",
    "\n",
    "    Returns:\n",
    "    - str: The abstract of the paper.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    abstract_block = soup.find('blockquote', {'class': 'abstract'})\n",
    "    if abstract_block:\n",
    "        abstract_text = abstract_block.text.replace(\"Abstract: \", \"\").strip()\n",
    "        return abstract_text\n",
    "    else:\n",
    "        print(f\"No abstract found for {url}\")\n",
    "        return None\n",
    "\n",
    "# Test\n",
    "url = \"https://arxiv.org/abs/2307.13106\"\n",
    "print(scrape_abstract(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4466e2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "284598e8243153347beb6d3b0f5691f7",
     "grade": true,
     "grade_id": "cell-862386d3cf70edf2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4783d9a5-b38d-4ccc-9cbe-f2269467e6d8",
   "metadata": {},
   "source": [
    "#### Task 2: Scrape all urls\n",
    "\n",
    "You will now use your function to scrape all the URLs that you collected in step 2.\n",
    "\n",
    "The following will provide instructions for how you can go about this task. However, there are several ways to do this, and you are free to choose your preferred method.\n",
    "\n",
    "Prepare your data:\n",
    "\n",
    "1. Load your list of dicts from step 2 (scraping_result.pkl)\n",
    "2. Use it to create a dataframe. \n",
    "3. Add a column 'scraped' which should be False for all rows, and a column 'abstract' that should be None for all rows.\n",
    "4. Store the dataframe persistently (e.g., by pickling it.)\n",
    "\n",
    "The scraping procedure:\n",
    "\n",
    "1. Load the persitent pickle as dataframe (so that if your computer crashes, the function will continue where you were)\n",
    "2. Repeat the following steps until there are no more rows with scraped == False:\n",
    "3. Fetch a random row with scraped == False\n",
    "4. Go to the URL and scrape the abstract.\n",
    "5. Set abstract column in the dataframe to the resulting abstract, set scraped to True.\n",
    "6. Store the dataframe persistently as a pickle. \n",
    "\n",
    "Remember: \n",
    "- You may use another strategy. However, since you will be scraping many pages, you should expect your scraper to encounter problems along the way. You therefore need to make sure that you regularly store the results persistently.\n",
    "- Make sure to handle any exceptions gracefully.\n",
    "- Be respectful toward the website owners: wait at least one second between each call. \n",
    "\n",
    "Your final result should be a dataframe stored as 'scraped_abstracts.df.pkl', with filled 'abstract' and 'scraped' columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbacc7-e0a1-4f98-8234-0ef5f76f3489",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<!-- [Evaluation: ]\n",
    "- Load dataframe as df\n",
    "- Check that the len of df = len of the result list from question 2. \n",
    "- Check that each line has an abstract, with len() > 100 e.g.\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ee8f157-0b13-4a9b-b4ff-56c738754500",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc342ab1d66dd404139011d72ebc4627",
     "grade": false,
     "grade_id": "cell-ac850524f08140c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping abstract from: https://arxiv.org/abs/2310.04824\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04465\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07577\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06856\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05689\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06778\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05421\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05421\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08433\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06061\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08455\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08532\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04824\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05598\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06475\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05432\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06475\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05472\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05396\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06778\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08133\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06061\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08433\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04897\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06556\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06269\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05070\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06633\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06009\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07715\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08455\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06556\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04875\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06269\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08532\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07613\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08133\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04997\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04824\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05070\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07577\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06391\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06009\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05998\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07563\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07806\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06361\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05396\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05070\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06257\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04875\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08133\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06856\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05998\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07613\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07806\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06257\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06856\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05070\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06257\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04997\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05396\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07888\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07629\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07625\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06391\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07715\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05484\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07625\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07516\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05476\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05998\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07563\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05936\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07099\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08532\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06633\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05472\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08795\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06391\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07577\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07888\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05432\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07715\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07715\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07629\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05689\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08349\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04465\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05936\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05476\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06633\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05476\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04897\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05689\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06056\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08433\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08795\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05421\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08433\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08455\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08133\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06361\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07629\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05998\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07613\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07915\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04897\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08349\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05472\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07915\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07625\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06633\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07516\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05396\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04628\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07888\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07099\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04997\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07915\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06361\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08532\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07806\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05598\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07516\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06391\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05476\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07613\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06778\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07629\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06269\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06556\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04425\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06061\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04425\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04465\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06269\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04897\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04465\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06009\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08795\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06009\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07563\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05432\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04824\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07625\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04875\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08795\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04739\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06056\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07516\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05484\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07563\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04465\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05472\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06475\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07915\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07577\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04425\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04997\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06475\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06257\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04875\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06556\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05432\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05484\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06361\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04875\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05689\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05396\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06056\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05484\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08455\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.04425\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05598\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05936\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07806\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08349\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06061\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07888\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06056\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06778\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05598\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.06856\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05421\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07099\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.08349\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.07099\n",
      "Scraping abstract from: https://arxiv.org/abs/2310.05936\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "with open('scraping_result.pkl', 'rb') as f:\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df['scraped'] = False\n",
    "df['abstract'] = None\n",
    "\n",
    "with open('initial_dataframe.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "def scrape_all_abstracts():\n",
    "    with open('initial_dataframe.pkl', 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    while df['scraped'].sum() < len(df):\n",
    "        random_row = df[df['scraped'] == False].sample(1)\n",
    "        index = random_row.index[0]\n",
    "        url = random_row['url'].values[0]\n",
    "        \n",
    "        print(f'Scraping abstract from: {url}')\n",
    "        \n",
    "        abstract = scrape_abstract(url)\n",
    "        \n",
    "        if abstract is not None:\n",
    "            df.at[index, 'abstract'] = abstract\n",
    "            df.at[index, 'scraped'] = True\n",
    "        \n",
    "            with open('initial_dataframe.pkl', 'wb') as f:\n",
    "                pickle.dump(df, f)\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    with open('scraped_abstracts.df.pkl', 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "scrape_all_abstracts()\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95ec0f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd9348c76775a31d0bc7c64630beda0c",
     "grade": true,
     "grade_id": "cell-d2927458cb5edcd5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
