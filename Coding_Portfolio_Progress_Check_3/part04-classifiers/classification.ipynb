{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "STUDENT_ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "In this exercise, we will use your newly discovered classification skills to classify whether a couple is likely to have a successful relationship based on their astrological signs.\n",
    "In this fictional data set, astrological signs do affect compatibility in some ways which you will have to discover. The effects of astrological signs which we have generated for this exercise may differ from real life, in that there are any.\n",
    "\n",
    "Classification is supervised learning, which means that we already know the outcome for some data, and use this data to train a model to classify unknown data.\n",
    "So, in our capacity as spiritual match-makers, we have compiled a list of relationships to train our classifier with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Task 1 (0 points)\n",
    "We have two .csv files with data: couples.csv, and persons.csv.\n",
    "Couples.csv contains the outcome we'd like to predict, but no useful variables to base our prediction on. It only tells us the id of the two partners.\n",
    "It's best if we have both X and Y in a single dataframe before we proceed.\n",
    "Create a dataframe called 'data' with the columns: couple_id, person_a, person_b, outcome, sign_a, sign_b, with the respective signs of persons a and b for each couple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43a8c6d41944710a04ffb757847d502b",
     "grade": true,
     "grade_id": "cell-249a474a627020c3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at the possible outcome variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the outcomes\n",
    "couples = pd.read_csv('couples.csv')\n",
    "sns.countplot(data=couples, x='outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Task 2 (0 points)\n",
    "As we can see, one possible outcome for couples is marriage. Although we can train a classifier to classify multiple outcome labels, let's keep it simple for now: We will simply classify whether a couple will be married or not. For this purpose, let's create a one-hot encoding: Create a column for data called 'married' which is equal to 1 if the couple is married and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5fc65d8e3255f5e579c7c17703d1e27",
     "grade": true,
     "grade_id": "cell-3bd942936038c0d3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Task 3 (0 points):\n",
    "Now we need to do the same to X: our input features. Since we have two categorical variables (sign_a and sign_b) with 12 possible values each, let's use sklearn's OneHotEncoder class to create vectors instead of manually creating 24 columns. Create a numpy array called 'features' of shape (5000, 24) which contains our one-hot encoded feature vectors.\n",
    "You can follow the first example of the class' documentation:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac91ac762ea3ed505dacf2e548ff2c95",
     "grade": true,
     "grade_id": "cell-e477f4c89f4c1f98",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Task 4 (0 points)\n",
    "Now we have everything we need: One-hot encoded features and the binary label 'married'.\n",
    "During the lecture you learned about binary logistic regression. Since our output variable is either 0 or 1, this seems like an ideal use case for it!\n",
    "Above, we imported LogisticRegression from sklearn. Have a look at the documentation, and implement it with default parameters for our data:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "Don't worry about test and train sets yet; we'll train our model on all the data and then evaluate it on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4542435ba2ae1c185232cd024485aca8",
     "grade": true,
     "grade_id": "cell-ce91039524fa2833",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = features\n",
    "y = data['married']\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Task 5 (0 points)\n",
    "76% accuracy! That doesn't sound bad for a first attempt. But remember the zero-rate classifier? Let's have a look at what our baseline should be.\n",
    "Above, we plotted all possible outcome variables. Have a look what's more likely: married (1), or not married (0)? Then create a zero-rate classifier that always returns the most likely result.\n",
    "The estimated outcome value y is often denoted as Å·, which is why we call it y_hat here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b47df2fa4c5f9177e4a4bb84ae51b33",
     "grade": true,
     "grade_id": "cell-43ff1aaeec93c228",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def zero_rate(x) -> int:\n",
    "    \"\"\"\n",
    "    Takes the input vector x and then completely disregards it.\n",
    "\n",
    "    Returns:\n",
    "        y(int): Whether or not the couple is married.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "y_hat = [zero_rate(x) for x in features]\n",
    "# We imported accuracy_score from sklearn.metrics\n",
    "acc = accuracy_score(y, y_hat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no, our zero-rate classifier is just as accurate as our logistic regression classifier.\n",
    "It seems our standard logistic regression model could not predict marriage based on astrological signs with any accuracy higher than chance.\n",
    "Does that mean that the signs simply have to effect on courting outcome? That would perhaps be the conclusion if this was astronomy class, but we wouldn't give you such a boring dataset for classification class would we?\n",
    "Assume there is some way in which the signs of the two partners affect their relationship. How come our model did not pick up on those?\n",
    "Can you think of a way in which the features could be re-coded so that logistic regression would predict the outcome with higher accuracy?\n",
    "Hint: A possible solution is shown in the next code cell. Try to think of one yourself first, but if you cannot, figure out why the sample solution works and then explain it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1e09740e0af5c094d63454c72ce5670",
     "grade": false,
     "grade_id": "cell-cef668ff570f1ef6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Question 1: (1 point, 30-150 words)\n",
    "Why did logistic regression not achieve useful accuracy? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b0875d468399519d5a9b007f3d01952",
     "grade": true,
     "grade_id": "cell-b32743c5bf213f82",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sign pairs for each possible combination\n",
    "sign_combination = data['sign_a'] + '-' + data['sign_b']\n",
    "# Shape them into an array with n samples and a single feature\n",
    "sign_combination = np.asarray(sign_combination).reshape(-1, 1)\n",
    "# One-hot encode\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(sign_combination)\n",
    "features = enc.transform(sign_combination).toarray()\n",
    "# Train and evaluate our classifier on these new features\n",
    "X = features\n",
    "y = data['married']\n",
    "classifier = LogisticRegression(random_state=0).fit(X, y)\n",
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have marginally improved the accuracy of our model. Let's see if we can improve it further by building more complex models and taking more information into account.\n",
    "\n",
    "Another variable we have available is each person's last tarot reading. Let's see if we can improve out model by including this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the tarot information from persons to our data\n",
    "data['tarot_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "data['tarot_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "\n",
    "# Add the tarot columns to your features\n",
    "features = np.c_[features, data['tarot_a'].tolist()]\n",
    "features = np.c_[features, data['tarot_b'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate our classifier on these new features\n",
    "X = features\n",
    "y = data['married']\n",
    "classifier = LogisticRegression(random_state=0, max_iter=300).fit(X, y)\n",
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't seem to significantly increase our accuracy. Maybe the variable isn't very useful, or maybe we are not using it right. Let's explore a bit.\n",
    "First, let's plot the distribution over values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['tarot_a'], bins=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different tarot cards seem more or less uniformly distributed.\n",
    "Let's color this plot by outcome to see if there is really no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='tarot_b', hue='outcome', bins=22, multiple='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee6fa700fa5b924ebe96b8f07725b384",
     "grade": false,
     "grade_id": "cell-4249749b8e222869",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Question 2: (2 points, 50-200 words)\n",
    "Explain what you see in the histogram above. What conclusion about the effect of tarot cards on partnership outcomes can you detect visually? If there are any effects, how might you take them into account, since using a numerical regressor for tarot seemed not to work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d27a7734cf6174429d637f286c98fb10",
     "grade": true,
     "grade_id": "cell-7cc1d1659e5d6928",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1850445883730c71247c7be114427a60",
     "grade": false,
     "grade_id": "cell-d04597696cf936fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This function reimports the data. You can use to reset your data in case you manipulated it earlier.\n",
    "# It also adds two additional features which we have not previously used\n",
    "# DO NOT CHANGE this function; it will be used when evaluating your code below.\n",
    "def load_data(couples_file = 'couples.csv', persons_file = 'persons.csv'):\n",
    "    couples = pd.read_csv(couples_file)\n",
    "    persons = pd.read_csv(persons_file)\n",
    "    data = couples.copy()\n",
    "    data['sign_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['sign'].iat[0])\n",
    "    data['sign_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['sign'].iat[0])\n",
    "    data['tarot_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "    data['tarot_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "    data['color_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['favorite_color'].iat[0])\n",
    "    data['color_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['favorite_color'].iat[0])\n",
    "    data['animal_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['favorite_animal'].iat[0])\n",
    "    data['animal_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['favorite_animal'].iat[0])\n",
    "    return data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 (1 point):\n",
    "Complete the functions below. You have already written most of the required code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a968e6783f02924df2ecc3dbd36b08dd",
     "grade": false,
     "grade_id": "cell-17cf940729bade89",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_outcome(data):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        np.array of shape (n_samples)\n",
    "    \"\"\"\n",
    "    # Insert the code you wrote above which one-hot encodes the marriage status here\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return np.array(data['married'])\n",
    "\n",
    "# This function applies your transformations to the data.\n",
    "# You can improve this function with any transformations you think improve the data for ML.\n",
    "def transform_features(data):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        np.array of shape (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    # This is our code from above which one-hot encodes the sign combiation\n",
    "    sign_combination = data['sign_a'] + '-' + data['sign_b']\n",
    "    sign_combination = np.asarray(sign_combination).reshape(-1, 1)\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(sign_combination)\n",
    "    sign_features = enc.transform(sign_combination).toarray()\n",
    "    # Write code here which transforms tarot_a and tarot_b into useful features.\n",
    "    # Create a variable called tarot_features which is a numpy array of dimensions (n_samples, n_features)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Insert any additional features you'd like to add to your model here.\n",
    "    # These can be additional transformations of the variables used so far, or can use the variables we have not included so far.\n",
    "\n",
    "    # All features are combined here. If you generated more features, add them to the line below.\n",
    "    features = np.hstack((sign_features, tarot_features))\n",
    "    return features\n",
    "    \n",
    "y = transform_outcome(data)\n",
    "X = transform_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve your transform_features() function until logistic regression based on your features achieves an accuracy of at least 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85870cc5f931612a7a866fb5e565d8e0",
     "grade": false,
     "grade_id": "cell-083bf1f2e1085774",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run logistic regression with the new features you created with the function above.\n",
    "classifier = LogisticRegression(random_state=0, max_iter=300).fit(X, y)\n",
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe199a826c48dc3e3d88d454a05cdcd5",
     "grade": true,
     "grade_id": "cell-af8195fd617ad089",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 (1 point)\n",
    "We've tinkered quite a bit with our features now. What about our classification model? Regression is one of the supervised ML techniques you have learned, but there are of course many others.\n",
    "While each technique requires understanding to apply it well, technically implementing them is made quite easy by sklearn, especially when using default hyperparameters and optimization.\n",
    "Show us that you know how to use online documentation to implement other ML models below. These two classifiers should also achieve 80% accuracy or higher. See what how accurate you can get with each type of classifier.\n",
    "First, implement a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1672efaceab43aaf8fb4a9e325d7c755",
     "grade": false,
     "grade_id": "cell-6b0d51c7d5dff10a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Using the same features which you used for regression above, implement a random forest classifier and print the accuracy score.\n",
    "# Make sure it is called rf_classifier\n",
    "rf_classifier = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f2dd66c6efd6d2a43a6a9614191cf54",
     "grade": true,
     "grade_id": "cell-f20165f357946a80",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 (1 point)\n",
    "Second, implement a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f41c0f899aa166aac027e33afbdbf04",
     "grade": false,
     "grade_id": "cell-0c3cd743cb10df40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Using the same features which you used for regression above, implement a neural network, specifically a multilayer perceptron classifier, and print the accuracy score.\n",
    "# Implement a perceptron with at least 2 hidden layers, and preferably one which can be trained in under a minute on an average laptop.\n",
    "# Make sure it is named nn_classifier\n",
    "nn_classifier = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d0f58dee53fd4a7aeff91e2d8ae58d3",
     "grade": true,
     "grade_id": "cell-ec8d0386770612b3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 (2 points)\n",
    "So far, you have trained your models on all available data. This means that while you may achieve a great fit to the data you have, your model may be overfitted and perform poorly on new, unseen data. This final exercise will be evaluated with couples and individuals which you do not have access to. They are from the same population as your sample, so your model should work fine if you don't overfit. Implement any sklearn classification model you like (logistic regression recommended) with a test/train(/evaluate) split or cross-validation.\n",
    "\n",
    "Your model will be evaluated by accuracy score, so try to achieve as high a score as possible while avoiding overfitting.\n",
    "Please make sure your model is trained in a reasonable time frame on an average laptop (a few minutes maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ddeb015c4f5afee26920eedda50fdca",
     "grade": false,
     "grade_id": "cell-19ba6e4f4a468d12",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# If you are changing your features, either change the function transform_features above, or implement a new function named transform_features!\n",
    "# The unseen test data will be transformed by this function also!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Implement your model here. Make sure it is named final_classifier\n",
    "X = transform_features(data)\n",
    "y = transform_outcome(data)\n",
    "final_classifier = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e9cb51d497160e9a95168f4dc7292c7",
     "grade": true,
     "grade_id": "cell-6143ab97709344db",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d85977059bbede10de57dfa08df3eff",
     "grade": true,
     "grade_id": "cell-7888a4c46ec6b53b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done, you've completed all the exercises. Make sure to restart your kernal and rerun all cells once before submitting to ensure that the notebook will run as expected.\n",
    "Here is a checklist of all graded parts for you to check:\n",
    " - 1 pt - Question 1\n",
    " - 2 pt - Question 2\n",
    " - 1 pt - Task 1: The classifier achieves an accuracy of 80% or higher\n",
    " - 1 pt - Task 2: The random forest classifier achieves an accuracy of 80% or higher\n",
    " - 1 pt - Task 3: The perceptron classifier achieves an accuracy of 80% or higher\n",
    " - 2 pt - Task 4: Your chosen classifier achieves a high accuracy on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f9d6cf1e3d8195079a65c851de355134a77367bcd714b1a5d498c42d3c07114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
