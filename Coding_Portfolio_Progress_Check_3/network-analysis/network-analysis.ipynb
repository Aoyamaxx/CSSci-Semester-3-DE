{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d1fe1c",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "STUDENT_ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9d514",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35207b7b",
   "metadata": {},
   "source": [
    "# Social Network Analysis Assignment\n",
    "\n",
    "This assignment aims to familiarize you with the concepts and practical applications of social network analysis. You will be working with Python and the NetworkX library to create, analyze, and understand various types of networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b1284",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Create a Small Network\n",
    "\n",
    "**Objective:** Generate a network with 10 nodes and a density of 0.2 using NetworkX.\n",
    "\n",
    "**Instructions:**\n",
    "1. Calculate the number of edges `m` needed to achieve a density `d = 0.2` for a network of `n = 10` nodes using the formula:\n",
    "\n",
    "$$d = \\frac{2m}{n(n-1)}$$\n",
    "\n",
    "\n",
    "2. Create a graph in NetworkX in variable `G` and add the calculated number of edges.\n",
    "3. Ensure the network consists of one large component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354d813",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a124da0905fd645ee4978ba9997bb828",
     "grade": false,
     "grade_id": "cell-1fe3b85cd46552d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a38f73",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2913b7bc0878ff8a15fbdcb36ece4749",
     "grade": false,
     "grade_id": "cell-95f17935163453b0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "G = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f799d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bbe2308a5860271e4fa15c00b6e932f",
     "grade": true,
     "grade_id": "cell-92d3354e445151b7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(G) == nx.Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb967c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd9134a52d11da08d738fe1e20475b2d",
     "grade": true,
     "grade_id": "cell-58f2c4e1ed25a37c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "914eb25c",
   "metadata": {},
   "source": [
    "## Task 2: Create a Non-Small-World Network\n",
    "\n",
    "**Objective:** Write a script to generate a network that is not a small world. The network should have 500 nodes and at least 1000 edges, with an average shortest path length of at least 50.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a function `create_large_world_network` that generates a network according to the specified criteria.\n",
    "2. Ensure that the network is not a small world by design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d4e0d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e26ee2a5fa6d1ee70856fcd6ff3441b9",
     "grade": false,
     "grade_id": "cell-2e49422416ccacd2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_large_world_network():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return G\n",
    "\n",
    "G = create_large_world_network()\n",
    "\n",
    "print(f\"Nodes: {len(G.nodes())}; edges: {len(G.edges())}; average shortest path: {nx.average_shortest_path_length(G)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1273f94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6052f1bf66fa3a887736347030b2657",
     "grade": true,
     "grade_id": "cell-68eff0e5fe961fbd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e20fe58",
   "metadata": {},
   "source": [
    "## Task 3: Analyze the Florentine Families Network\n",
    "\n",
    "**Objective:** Analyze the Florentine families network to find the most central node in terms of PageRank, betweenness, degree, and eigenvector centrality.\n",
    "\n",
    "**Instructions:**\n",
    "1. Load the Florentine families dataset (Padget & Ansell, 1993).\n",
    "2. Calculate and return the most central node for each centrality measure (PageRank, Betweenness, Degree, and Eigenvector centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb37f6b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac18be4d5f7fdbee4dd4c847f15d06d9",
     "grade": false,
     "grade_id": "cell-369770dcd2179dd2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def find_most_central_nodes(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return top_pagerank, top_betweenness, top_degree, top_eigenvector\n",
    "\n",
    "top_pagerank, top_betweenness, top_degree, top_eigenvector = find_most_central_nodes(G)\n",
    "\n",
    "G = nx.florentine_families_graph()\n",
    "\n",
    "print(f\"Node with highest PageRank centrality: {top_pagerank}\")\n",
    "print(f\"Node with highest Betweenness centrality: {top_betweenness}\")\n",
    "print(f\"Node with highest Degree centrality: {top_degree}\")\n",
    "print(f\"Node with highest Eigenvector centrality: {top_eigenvector}\")\n",
    "\n",
    "# Visualize the network\n",
    "nx.draw(G, with_labels=True, node_color='lightblue', edge_color='gray', font_size=10, node_size=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903ba6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce0ae6a2aa1ccf51297d3f3f25961da3",
     "grade": true,
     "grade_id": "cell-3d7ac0c7c417aee0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afe7e3c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Generate a Graph with Clustered Communities\n",
    "\n",
    "**Objective:** Write a function to generate a graph with N clusters, each containing M nodes. The nodes in each cluster should be randomly connected with density D - with connections going between randomly selected nodes. The clusters should be linked with each other, to produce a single component, with as few connections as possible.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a function `create_clustered_graph` that generates a graph according to the description above.\n",
    "2. Analyze the graph using Louvain community detection to examine the resulting modularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26e1f4",
   "metadata": {},
   "source": [
    "Now generate two networks with your algorithm. One with 3 clusters, and one with 10 clusters. The other parameters should be same as above.\n",
    "\n",
    "Run Louvain community detection on both. Which of the networks has a higher modularity? What do you make of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb119811",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cea77b28d74dcb1ba543ff8e0302430",
     "grade": false,
     "grade_id": "cell-fea8bc1efeb7adc6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from community import community_louvain\n",
    "\n",
    "def create_clustered_graph(N, M, D):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return G\n",
    "\n",
    "def identify_louvain_modularity(G):\n",
    "    #Use Louvain to identify communities in the graph, and print out the \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "num_clusters = 5\n",
    "nodes_per_cluster = 20\n",
    "intra_density = 1\n",
    "G = create_clustered_graph(num_clusters, nodes_per_cluster, intra_density)\n",
    "\n",
    "modularity = identify_louvain_modularity(G)\n",
    "print(f\"The identified modularity is {modularity}.\")\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G, with_labels=True, node_color='lightblue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11d9cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72cf3710cc70cd10f690abfea898e72b",
     "grade": true,
     "grade_id": "cell-5b8c4bf89ea8a0c1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06bbc47c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Twitter Retweet Network Analysis\n",
    "\n",
    "**Objective:** Create a network from a Twitter dataset and analyze it to find the most central politicians and calculate the weighted homophily based on party.\n",
    "\n",
    "**Instructions:**\n",
    "1. Load the Twitter dataset, sweden_2018.df.pickle, and create a network where nodes represent politicians and edges represent retweets.\n",
    "2. Calculate the weighted homophily of the network. The weighted homophily is here the tendency for individuals of the same party to form connections with one another. \n",
    "3. Identify the most central politicians using different centrality measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c979774b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e923a87609af3c42f3cbfa3d5ca79f3f",
     "grade": false,
     "grade_id": "cell-1aeb947b96bf4b36",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_pickle('sweden_2018.df.pickle')\n",
    "display(df.head())\n",
    "\n",
    "def extract_retweeted_username(tweet):\n",
    "\n",
    "    pattern = r'RT @(\\w+):'\n",
    "    match = re.search(pattern, tweet)\n",
    "    if match:\n",
    "        return match.group(1)  # Returns the captured username\n",
    "    return None  # Returns None if no match is found\n",
    "\n",
    "#1. Extract retweets\n",
    "#2. Include only retweets of politicians that have also sent at least one message. \n",
    "#3. Count the number of messages from each user to each user\n",
    "#4. Create a weighted network from the resulting dataframe. The nodes should have include the party name as an attribute.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "nx.draw(G)\n",
    "\n",
    "def calculate_weighted_homophily(graph, attribute):\n",
    "    # We now want to know the homophily of the network; that is, how much likelier nodes are to connect with nodes of the same party.\n",
    "    # The weighted homophily is defined as the sum of edge weights that go between nodes with the same attributes, divided by the total edge weight.\n",
    "    # Unfortunately, there is no built-in function for weighted homophily in networkx, so you have to write your own function!\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return homophily_ratio\n",
    "\n",
    "homophily = calculate_weighted_homophily(G, 'party')\n",
    "\n",
    "print(f\"The resulting homophily is {homophily}.\")\n",
    "\n",
    "def find_most_central_nodes(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return top_pagerank, top_betweenness, top_degree, top_eigenvector\n",
    "\n",
    "top_pagerank, top_betweenness, top_degree, top_eigenvector = find_most_central_nodes(G)\n",
    "\n",
    "print(\"Node with highest PageRank centrality:\", top_pagerank)\n",
    "print(\"Node with highest Betweenness centrality:\", top_betweenness)\n",
    "print(\"Node with highest Degree centrality:\", top_degree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8c207",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2351246dd24b1c1d97ef3160d9f27563",
     "grade": true,
     "grade_id": "cell-3a214a76eef90a38",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
