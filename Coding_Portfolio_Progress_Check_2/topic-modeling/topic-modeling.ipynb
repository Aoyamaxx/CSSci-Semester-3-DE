{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f02b405",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ca3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "STUDENT_ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292538f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338a427",
   "metadata": {},
   "source": [
    "*Objective*: Apply topic modelling techniques, such as Latent Dirichlet Allocation (LDA), to analyze and interpret the primary topics present in a collection of online news articles.\n",
    "\n",
    "Topic modelling is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. It is a frequently used text-mining tool for the discovery of hidden semantic structures in a text body. This assignment involves implementing and interpreting LDA topic modelling on a dataset of online news articles to understand the prevalent themes and topics.\n",
    "\n",
    "For this task, you will use the \"Fake news\" dataset, which contains information about a large number of fake news articles. The dataset is available here: https://www.kaggle.com/datasets/mrisdal/fake-news.\n",
    "\n",
    "1. Prepare: Explore the dataset\n",
    "2. Pre-process the text data\n",
    "3. Implement the LDA model\n",
    "4. Analyze the topics and interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925637f",
   "metadata": {},
   "source": [
    "### Setup and requirements\n",
    "First, make sure that you have the needed libraries for Python correctly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b4b5a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ede09c3d5cc5dd7a861761fe3969ce2",
     "grade": false,
     "grade_id": "cell-dd19779ac384bb27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#!pip install numpy pandas matplotlib sklearn gensim nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec19996",
   "metadata": {},
   "source": [
    "## 1. Prepare and Explore the Dataset (1 point)\n",
    "\n",
    "The first step is to download and load the dataset. Familiarize yourself with its structure and content. Understand the kind of articles included, and how the data is organized.\n",
    "\n",
    "\n",
    "1. Load the dataset using pandas.\n",
    "2. Explore the dataset. What columns does it include? How are the articles represented?\n",
    "3. For exploration purposes and initial model training take 15-35% sample of dataframe using the sample method in pandas\n",
    "4. Store your dataset in the variable named `news_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5fba8d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c08ae297a579d812729903d4d5972bb7",
     "grade": false,
     "grade_id": "cell-98f59e03d8e80d78",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "news_df = ...\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b7c40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66e5ae238c748c57795da1f5433edb7d",
     "grade": true,
     "grade_id": "cell-b34716260ad1c575",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 1949 <= len(news_df) <= 4550, \"You should sample between 15-35% of the dataset.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d06419",
   "metadata": {},
   "source": [
    "### Question 1: Dataset Exploration (1 point)\n",
    "\n",
    "\n",
    "What are the key characteristics of this dataset? Describe the dataset in terms of its size, variety of articles, and any other notable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706024b1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9575b390b4cc35d1a33a152c7056b8b",
     "grade": true,
     "grade_id": "cell-a06327cbfa6e1933",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55315fc0",
   "metadata": {},
   "source": [
    "## 2. Pre-process the Text Data\n",
    "\n",
    "Before applying topic modelling, it's crucial to pre-process the text data. This involves cleaning the text, removing stop words, and converting the text into a suitable format for analysis.\n",
    "\n",
    "1. Complete the `preprocess_text()` function to clean the text data (remove punctuation, lowercase, tokenize, lemmatize).\n",
    "2. Remove stopwords using the NLTK library.\n",
    "3. Create a corpus required for the LDA model using the gensim package and save it in variable `corpus`.\n",
    "3. Convert the cleaned text into a document-term matrix using the gensim package and save it in variable `doc_term_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790c923",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "553359e51d2d24c62caad51bd362dd2d",
     "grade": false,
     "grade_id": "cell-452f92f52df1cee7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "corpus = ...\n",
    "doc_term_matrix = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae420a3",
   "metadata": {},
   "source": [
    "Public test (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec4579",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61584de91cadb7e4ec018fe1b030d6fd",
     "grade": true,
     "grade_id": "cell-7a6a25d384681e03",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(doc_term_matrix) == list, \"doc_term_matrix should be a list of lists\"\n",
    "assert type(corpus) == gensim.corpora.dictionary.Dictionary, \"corpus should be a gensim.corpora.dictionary.Dictionary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b85f0",
   "metadata": {},
   "source": [
    "Hidden tests (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f65cf6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "073ac1768af564b2deb85b71fc6c0983",
     "grade": true,
     "grade_id": "cell-becc487e03b5adcd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5094568c",
   "metadata": {},
   "source": [
    "### Question 2: Pre-processing Importance (2 points)\n",
    "\n",
    "Why is pre-processing important in topic modelling? Describe how each step in the pre-processing pipeline contributes to the overall analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83394648",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a763c1df97ef58ae88b83a606ae2aed",
     "grade": true,
     "grade_id": "cell-f075d1d9356f0fca",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7647e",
   "metadata": {},
   "source": [
    "## 3. Implement the LDA Model (1 point)\n",
    "\n",
    "Now, it's time to implement the LDA model using the Gensim library. Be sure to check out the documentation for hyperparameter settings.\n",
    "\n",
    "1. Choose the number of topics for the model. This is a crucial step and may require some experimentation.\n",
    "2. Train the LDA model on the dataset.\n",
    "3. Save the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27446851",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42d5c65fabe90db6029d1e7cffeecd42",
     "grade": false,
     "grade_id": "cell-5dcaf729b499fc30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lda_model = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73eb16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3be4204c1ea48dfdf3a19157a08669a",
     "grade": true,
     "grade_id": "cell-d6e66bfedef344aa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(lda_model) == gensim.models.ldamodel.LdaModel, \"lda_model should be a gensim.models.ldamodel.LdaModel\"\n",
    "lda_model.save('lda_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122d3e6",
   "metadata": {},
   "source": [
    "### Question 3: Model Parameters (2 points)\n",
    "\n",
    "Discuss the choice of number of topics for the LDA model. How does this choice impact the model's performance and the interpretability of the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca03053",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25e479cecd029ff3c4976c7de22369f8",
     "grade": true,
     "grade_id": "cell-7ac44640f28f4dc1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e01ea5",
   "metadata": {},
   "source": [
    "## 4. Analyze Topics and Interpret Results (1 point)\n",
    "\n",
    "Finally, analyze the topics produced by the LDA model and interpret the results.\n",
    "\n",
    "1. Use the LDA model to identify the main topics in the dataset.\n",
    "2. For each topic, examine the most representative words.\n",
    "4. Interpret the topics: What themes or subjects do they represent?\n",
    "\n",
    "### Question 4: Topic Interpretation\n",
    "\n",
    "Interpret the topics generated by the LDA model. How coherent are the topics? What do they tell us about the content of the dataset? Does this model need improvement by modifying parameters, using further pre-processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3983b1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6221f043a19d983619a2037ac8ab415f",
     "grade": true,
     "grade_id": "cell-b2dff7e06fc82bd6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce4c80",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf2f620e1116755891b494ba7d0af986",
     "grade": true,
     "grade_id": "cell-f5a6c428bb4b0f8e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff7f77f",
   "metadata": {},
   "source": [
    "## Question 5: Improving Preprocessing for Topic Modeling (1 point)\n",
    "\n",
    "### Objective:\n",
    "Enhance your understanding and skills in preprocessing text data for topic modeling. You will focus on two key areas: \n",
    "1. Subsetting posts by language (focusing on English).\n",
    "2. Enriching the list of stopwords specific to your dataset for more effective topic modeling by adding custom stopwords. Analyze the results to identify irrelevant or overly common words that could be added to your stopwords list.\n",
    "3. **Re-run Topic Modeling**: Apply the enriched stopwords list and re-run the topic modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98ce57",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f5d5247d657b77caa306959d724d0d4",
     "grade": true,
     "grade_id": "cell-20f891863be76484",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# subset dataset by english articles\n",
    "# news_df = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "custom_stopwords = set([])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b778b45",
   "metadata": {},
   "source": [
    "Does this additional preprocessing improve the topic model output? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eded2c1-0596-4228-b17d-e5cadc38b6d8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9650f3385095a74237c5ca125f6d4af0",
     "grade": true,
     "grade_id": "cell-a31aca76ea2afbe0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc00be",
   "metadata": {},
   "source": [
    "## Question 6. Assessing LDA Model Coherence (2 points)\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this exercise, you will assess the coherence of an LDA topic model using Gensim's coherence measures. Coherence measures help in evaluating how well the topics generated by the model are interpretable and semantically meaningful.\n",
    "\n",
    "### Task\n",
    "\n",
    "1. **Implement an LDA Model**: Using the \"Fake news\" dataset, implement an LDA model as done in the previous exercises.\n",
    "2. **Compute Coherence Score**: Calculate the coherence score of your model using Gensim's CoherenceModel (https://radimrehurek.com/gensim/models/coherencemodel.html).\n",
    "3. **Experiment with Different Number of Topics**: Experiment with different numbers of topics (e.g., 5, 10, 15 or 10, 50, 100 or whatever range you deem likely for the given data) and assess how the coherence score changes. Write a function that computes a coherence score for each model and plot the coherence scores associated with each topic number value (1 point).\n",
    "4. **Interpret Results**: Based on the coherence scores, determine the optimal number of topics for the model (1 point).\n",
    "\n",
    "### Assessment Criteria\n",
    "\n",
    "- Quality of LDA model implementation.\n",
    "- Correct calculation and interpretation of coherence scores.\n",
    "- Thoughtful experimentation with different numbers of topics and analysis of the impact on coherence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521724f0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe4387f4926e8561eef9746a11c5ab03",
     "grade": true,
     "grade_id": "cell-29b1683e1a1c0550",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Function to compute coherence score\n",
    "def compute_coherence(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Applying the function to our dataset\n",
    "model_list, coherence_values = compute_coherence(dictionary=dictionary, corpus=doc_term_matrix, texts=news_df['cleaned_text'].str.split(), start=20, limit=100, step=10)\n",
    "\n",
    "# Plotting coherence scores\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93d418-8821-4917-869d-0ed54bb8586a",
   "metadata": {},
   "source": [
    "What is the optimal number of topics for your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b109b45-93ed-4379-9407-137c358929e6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a09e4fc2626ba2cebedfd573b8a4bb29",
     "grade": true,
     "grade_id": "cell-9237751dd218cf6e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c14865",
   "metadata": {},
   "source": [
    "## Question 7: Fitting the Final LDA Model on the Entire Dataset (4 points)\n",
    "\n",
    "### Objective:\n",
    "Having identified the optimal number of topics using the coherence model in Gensim, your task now is to apply this knowledge to fit the final LDA (Latent Dirichlet Allocation) model on the entire dataset.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Optimal Number of Topics**:\n",
    "   - Recall the optimal number of topics you determined using the coherence model on a sample of your dataset.\n",
    "   \n",
    "2. **Preprocess the Full Dataset**:\n",
    "   - Ensure that the entire dataset is properly preprocessed (tokenization, removing stopwords, etc.).\n",
    "   - Create a dictionary and a bag-of-words corpus using the full dataset.\n",
    "\n",
    "3. **Fit the LDA Model**:\n",
    "   - Instantiate and train the LDA model on the entire dataset using the optimal number of topics you previously determined.\n",
    "   - Use the same model parameters that were most effective during your experimentation with the sample.\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - Briefly evaluate the model by examining the coherence score on the full dataset.\n",
    "   - Display the top words for each topic and provide a brief interpretation.\n",
    "\n",
    "5. **Reflection**:\n",
    "   - Reflect on any differences observed in topic quality and coherence when the model is applied to the entire dataset versus the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673e197",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f60e39836c029ea56c19fdaedb2c2d32",
     "grade": true,
     "grade_id": "cell-93e0c36b6e485390",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
